{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac408b5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc639f114a2869c4d2f09a3fb9299a08",
     "grade": false,
     "grade_id": "cell-b00828259c8e42e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# RO47019: Intelligent Control Systems Practical Assignment\n",
    "* Period: 2024-2025, Q4\n",
    "* Course homepage: https://brightspace.tudelft.nl/d2l/home/682445\n",
    "* Instructor: Cosimo Della Santina (C.DellaSantina@tudelft.nl)\n",
    "* Teaching assistant: Niels Stienen (N.L.Stienen@student.tudelft.nl)\n",
    "* (c) TU Delft, 2025\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE` and remove `raise NotImplementedError()` afterwards. Moreover, if you see an empty cell, please **do not** delete it, instead run that cell as you would run all other cells. Finally, please **do not** add any extra cells to this notebook or change the existing cells unless you are explicitly asked to do so.\n",
    "\n",
    "Please fill in your name(s) and other required details below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please fill in your names, student numbers, netID, and emails below.\n",
    "STUDENT_1_NAME = \"\"\n",
    "STUDENT_1_STUDENT_NUMBER = \"\"\n",
    "STUDENT_1_NETID = \"\"\n",
    "STUDENT_1_EMAIL = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba32571",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "042927213b84aa368aa3ea72caa4cb60",
     "grade": true,
     "grade_id": "cell-9f148ec62e0de49c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note: this block is a check that you have filled in the above information.\n",
    "# It will throw an AssertionError until all fields are filled\n",
    "assert STUDENT_1_NAME != \"\"\n",
    "assert STUDENT_1_STUDENT_NUMBER != \"\"\n",
    "assert STUDENT_1_NETID != \"\"\n",
    "assert STUDENT_1_EMAIL != \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af317a94",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e1ac82f761cd49715da5f2adb9bea9f2",
     "grade": false,
     "grade_id": "cell-4ea391677951116c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### General announcements\n",
    "\n",
    "* Do *not* share your solutions (also after the course is finished), and do *not* copy solutions from others. By submitting your solutions, you claim that you alone are responsible for this code.\n",
    "\n",
    "* Please post your questions regarding this assignment in the correct support forum on Brightspace, this way everybody can benefit from the response. Please note that it is **not** allowed to post any code relating to solution attempts. If you do have a particular question that you want to ask directly, please use the scheduled Q&A hours to ask the TA or if not possible otherwise, send an email to the instructor or TA.\n",
    "\n",
    "* This notebook will have in various places a line that throws a `NotImplementedError` exception. These are locations where the assignment requires you to adapt the code! These lines are just there as a reminder for you that you have not yet adapted that particular piece of code, especially when you execute all the cells. Once your solution code replaced these lines, it should accordingly *not* throw any exceptions anymore.\n",
    "\n",
    "* This [Jupyter notebook](https://jupyter.org/) uses `nbgrader` to help us with automated tests. `nbgrader` will make various cells in this notebook \"uneditable\" or \"unremovable\" and gives them a special id in the cell metadata. This way, when we run our checks, the system will check the existence of the cell ids and verify the number of points and which checks must be run. While there are ways that you can edit the metadata and work around the restrictions to delete or modify these special cells, you should not do that since then our nbgrader backend will not be able to parse your notebook and give you points for the assignment. \n",
    "\n",
    "* Please note that the above mentioned _read-only_ protection only works in Jupyter Notebook, and it does not work if you open this notebook in another editor (e.g., VSCode, PyCharm, etc.). Therefore, we recommend that you only use Jupyter Notebook for this course. If you use any other editor, you may accidentally delete cells, modify the tests, etc., which would cause you to lose points.\n",
    "\n",
    "* If you edit a function that is imported in another notebook, you need to **restart the kernel** of the notebook where you are using the function. Otherwise, the changes will not be effective.\n",
    "\n",
    "* **IMPORTANT**: Please make sure that your code executes without any errors before submitting the notebook. An easy way to ensure this is to use the validation script as described in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c956945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6faead90",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c35ac1c89c783d7b22071eb7d53c6ac",
     "grade": false,
     "grade_id": "cell-45ed33bd87d9d3aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task 3g - Behavioural Cloning of a reference trajectory (8.5p)\n",
    "**Authors:** Giovanni Franzese, Lorenzo Lyons (L.Lyons@tudelft.nl)\n",
    "\n",
    "In this part of the task, we imagine to have a dataset that is coming from a robot that is executing a certain behaviour and the only thing that we can obseve is \n",
    "- the reference trajectory\n",
    "\n",
    "We are going to use a GP to model the desired delta angles as a function of the angles and then we are going to use the GP to predict them during control, converting the delta in torque using a proportional controller. This is usually refereed to as **Behavioural Cloning**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab35657",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e0534a0b7cc0b7ee94b6db4cf1f13c1",
     "grade": false,
     "grade_id": "cell-a1f334182de3c7c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# import all Python modules\n",
    "from distutils.util import strtobool\n",
    "from functools import partial\n",
    "import gpytorch\n",
    "from gpytorch.models import ApproximateGP\n",
    "from IPython.display import display, HTML  # For animations in the notebook\n",
    "import jax\n",
    "\n",
    "jax.config.update(\"jax_platforms\", \"cpu\")  # set default device to 'cpu'\n",
    "jax.config.update(\"jax_enable_x64\", True)  # double precision\n",
    "from jax import Array\n",
    "from jax import numpy as jnp\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch.autograd.functional import jacobian\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from jax_double_pendulum.analysis import *\n",
    "from jax_double_pendulum.dynamics import dynamical_matrices\n",
    "from jax_double_pendulum.motion_planning import (\n",
    "    generate_ellipse_trajectory,\n",
    "    ELLIPSE_PARAMS,\n",
    ")\n",
    "from jax_double_pendulum.robot_parameters import ROBOT_PARAMS\n",
    "from jax_double_pendulum.robot_simulation import simulate_robot\n",
    "from jax_double_pendulum.utils import normalize_link_angles\n",
    "from jax_double_pendulum.visualization import animate_robot\n",
    "\n",
    "# define boolean to check if the notebook is run for autograding\n",
    "AUTOGRADING = strtobool(os.environ.get(\"AUTOGRADING\", \"false\"))\n",
    "\n",
    "# define folder where to save animations and plots\n",
    "outputs_dir = Path(\"outputs\")\n",
    "outputs_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5ac6e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b10c9fa64b866cdb320ac572b402c42",
     "grade": false,
     "grade_id": "cell-acde6d4601facb9c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Generate the reference trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b741841e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01fdc5be7b67ba31a3cc0ed475350a45",
     "grade": false,
     "grade_id": "cell-59b6ef693bf11fd4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# simulation parameters\n",
    "sim_duration = 15.0  # [s]\n",
    "sim_dt = 1e-2  # [s]\n",
    "\n",
    "# define time steps\n",
    "t_ts = sim_dt * jnp.arange(int(sim_duration / sim_dt))\n",
    "\n",
    "# generate reference trajectory\n",
    "traj_ts = generate_ellipse_trajectory(\n",
    "    rp=ROBOT_PARAMS,\n",
    "    t_ts=t_ts,\n",
    "    **ELLIPSE_PARAMS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d8bb3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "51d3bdb104f4895ac6e786d9331f79d8",
     "grade": false,
     "grade_id": "cell-8c9278c77501969c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Generate the dataset by extracting the angle and delta angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d135d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c996fd97655061e6222367553adad6c",
     "grade": false,
     "grade_id": "cell-8d88874418e417ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "reference_angle = np.array(traj_ts[\"th_ts\"])\n",
    "step_ahead = 1\n",
    "reference_angle[:, 1] = (\n",
    "    reference_angle[:, 1] - reference_angle[:, 0]\n",
    ")  # we prefer to control the second link angle by considering the relative angle with respect to the first link\n",
    "reference_angle_delta = (\n",
    "    reference_angle[step_ahead:, :] - reference_angle[:-step_ahead, :]\n",
    ")\n",
    "reference_angle[:, 0] = np.angle(np.exp(1j * reference_angle[:, 0]))\n",
    "reference_angle[:, 1] = np.angle(np.exp(1j * reference_angle[:, 1]))\n",
    "reference_angle = reference_angle[:-step_ahead, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9854cf06",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7e5ec3d390c00f1d08b03bb874e7426",
     "grade": false,
     "grade_id": "cell-9c8fe82ac87f6a26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Eximine the dataset by priting the angles and the delta angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d2f20a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c61a5d8e784e7b70c61a451ad6c8a51d",
     "grade": false,
     "grade_id": "cell-2c61c651db39a432",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(reference_angle[:, 0])\n",
    "plt.plot(reference_angle[:, 1])\n",
    "plt.legend([\"q1\", \"q2_rel\"])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(reference_angle_delta[:, 0])\n",
    "plt.plot(reference_angle_delta[:, 1])\n",
    "plt.legend([\"delta_q1\", \"delta_q2_rel\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b46579",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "355f03875e3b9faca849cc3e55648637",
     "grade": false,
     "grade_id": "cell-5ffc09826b17f582",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b2cb37",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b26bc0078e165b88bb560e5c26b7ab5d",
     "grade": false,
     "grade_id": "cell-cf269b317f266bd6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = reference_angle\n",
    "Y = reference_angle_delta\n",
    "X = torch.tensor(X).float()\n",
    "Y = torch.tensor(Y).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a512dd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef7e0360784c71ec30cc280f7eed35eb",
     "grade": false,
     "grade_id": "cell-385ee801cff7be14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3g-1 DEFINE A KERNEL FUNCTION THAT IS PERIODIC WITH A PERIOD OF 2 PI. (1p)\n",
    "Since we work with angles, we know that the angles are periodic with a period of 2 pi. Using the right kernel function will help the Gaussian Process (GP) to model the data.\n",
    "Don't forget to add the scale kernel in the front of the periodic kernel and to have it to be batch independent like in the previous notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53d1daa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0cb5fc97cf022902448987e1e00850f",
     "grade": false,
     "grade_id": "cell-25091fd86a6052a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Cheat sheet:**\n",
    "\n",
    "How to define a periodic kernel that is periodic with a period of 2pi:\n",
    "``` python \n",
    "PeriodicKernel(period_length_constraint=gpytorch.constraints.Interval(lower_bound=torch.tensor([2* torch.pi-0.01]), upper_bound=torch.tensor([2* torch.pi+0.01]), initial_value=torch.tensor([2* torch.pi]))) \n",
    "```\n",
    "\n",
    "How to print the hyperparameters of a periodic kernel:\n",
    "``` python\n",
    "gp.covar_module.base_kernel.period_length\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a82a5c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf20e06d64842d98af92629ba6ae101d",
     "grade": true,
     "grade_id": "cell-3bab4b444e47dadc",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class MultitaskGPModel(ApproximateGP):\n",
    "    def __init__(self, num_tasks, inducing_points, constant_mean=False):\n",
    "        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\n",
    "            inducing_points.size(-2), batch_shape=torch.Size([num_tasks])\n",
    "        )\n",
    "\n",
    "        variational_strategy = (\n",
    "            gpytorch.variational.IndependentMultitaskVariationalStrategy(\n",
    "                gpytorch.variational.VariationalStrategy(\n",
    "                    self,\n",
    "                    inducing_points,\n",
    "                    variational_distribution,\n",
    "                    learn_inducing_locations=True,\n",
    "                ),\n",
    "                num_tasks=num_tasks,\n",
    "                task_dim=-1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        super().__init__(variational_strategy)\n",
    "\n",
    "        if constant_mean:\n",
    "            self.mean_module = gpytorch.means.ConstantMean(\n",
    "                batch_shape=torch.Size([num_tasks])\n",
    "            )\n",
    "        else:\n",
    "            self.mean_module = gpytorch.means.ZeroMean(\n",
    "                batch_shape=torch.Size([num_tasks])\n",
    "            )\n",
    "\n",
    "        # self.covar_module = gpytorch.kernels.ScaleKernel(, batch_shape=torch.Size([num_tasks]))\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The forward function should be written as if we were dealing with each output\n",
    "        # dimension in batch\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894c8469",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad0620a06ab1af96f2cb19bd4ea2c5f7",
     "grade": false,
     "grade_id": "cell-a449cd608a176d04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3g-2 Define the gp and the likelihood inside the model (1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1aa3b7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1428639ed4a96d87ca9a574945b9ea85",
     "grade": true,
     "grade_id": "cell-fb1002bfc9caa98b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, X, Y, n_ind=100, batch_size=256):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        # number of inducing points\n",
    "        unique_random_indices = torch.randperm(len(X))[:n_ind]\n",
    "        inducing_points = X[unique_random_indices]\n",
    "        self.inducing_points = inducing_points\n",
    "        self.batch_size = batch_size\n",
    "        self.is_cuda = False\n",
    "        self.rmse_loss_vec = np.array([])\n",
    "\n",
    "        self.gp = None\n",
    "        self.likelihood = None\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def to_cuda(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.gp = self.gp.cuda()\n",
    "            self.likelihood = self.likelihood.cuda()\n",
    "            self.X = self.X.cuda()\n",
    "            self.Y = self.Y.cuda()\n",
    "            self.is_cuda = True\n",
    "        else:\n",
    "            print(\"Cuda not available\")\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.is_cuda:\n",
    "            x = x.cuda()\n",
    "        return self.likelihood(self.gp(x))\n",
    "\n",
    "    def variance_fun(self, x):\n",
    "        predictions = self.gp(x)\n",
    "        return predictions.variance[0, :]\n",
    "\n",
    "    def derivative_variance(self, x):\n",
    "        if self.is_cuda:\n",
    "            x = x.cuda()\n",
    "        jac = jacobian(self.variance_fun, x).detach()\n",
    "        jac = jac.reshape(-1, x.size(1))\n",
    "        return torch.diag(jac)\n",
    "\n",
    "    def train(self, num_epochs=400):\n",
    "        self.gp = self.gp.double()\n",
    "        self.likelihood = self.likelihood.double()\n",
    "        self.X = self.X.double()\n",
    "        self.Y = self.Y.double()\n",
    "        self.train_dataset = TensorDataset(self.X, self.Y)\n",
    "        self.train_loader = DataLoader(\n",
    "            self.train_dataset, batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "        self.gp.train()\n",
    "        self.likelihood.train()\n",
    "\n",
    "        optimizer = torch.optim.Adam(\n",
    "            [\n",
    "                {\"params\": self.gp.parameters()},\n",
    "                {\"params\": self.likelihood.parameters()},\n",
    "            ],\n",
    "            lr=0.01,\n",
    "        )\n",
    "\n",
    "        # Our loss object. We're using the VariationalELBO\n",
    "        self.mll = gpytorch.mlls.VariationalELBO(\n",
    "            self.likelihood, self.gp, num_data=self.Y.size(0)\n",
    "        )\n",
    "\n",
    "        # to plot the loss function\n",
    "        self.rmse_loss_vec = np.zeros(num_epochs)\n",
    "\n",
    "        for i in tqdm(range(num_epochs)):\n",
    "            # Within each iteration, we will go over each minibatch of data\n",
    "            loss_sum = 0.0\n",
    "            for x_batch, y_batch in self.train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                output = self.gp(x_batch)\n",
    "                loss = -self.mll(output, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_sum += loss.detach().cpu()\n",
    "            self.rmse_loss_vec[i] = (\n",
    "                torch.sqrt(loss_sum / len(self.train_loader)).detach().item()\n",
    "            )\n",
    "\n",
    "    def plot_convergence(self, experiment_name: str):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(self.rmse_loss_vec, label=\"loss\")\n",
    "        ax.set_xlabel(\"Epochs\")\n",
    "        ax.set_ylabel(r\"Trainings RMSE for $\\hat{\\ddot{\\theta}}$ [rad/s^2]\")\n",
    "        plt.savefig(\n",
    "            str(outputs_dir / f\"task_3g_training_convergence_{experiment_name}.pdf\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e335684",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd5371afe7f879bb1c0bfda5b56eb35b",
     "grade": false,
     "grade_id": "cell-d67c9119f658dc4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3g-3 Define the model and train it (0.5p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c934dec",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd40e641b332925465ec68f4db78c056",
     "grade": true,
     "grade_id": "cell-6845387c6d310dea",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# controller_model =\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b884f2f9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e39a198380105ea55a32725bca2e9370",
     "grade": false,
     "grade_id": "cell-e847eef0164b892a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3g-4 Let's use the model to control the robot (1p)\n",
    "In the next cell you have use the mean preiction of the output of the GP to control the robot. You also have to tune the proportional gain for the proportional controller. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7617bc",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e06d7b5dbd244946dfaed8174c1e97a",
     "grade": true,
     "grade_id": "cell-6c5b6402d89f304f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# run closed-loop simulation with GP-based controller\n",
    "sim_dt = 0.01\n",
    "sim_duration = 12.0\n",
    "\n",
    "# define time steps\n",
    "t_ts = sim_dt * jnp.arange(int(sim_duration / sim_dt))\n",
    "\n",
    "# generate reference trajectory\n",
    "traj_ts = generate_ellipse_trajectory(\n",
    "    rp=ROBOT_PARAMS,\n",
    "    t_ts=t_ts,\n",
    "    **ELLIPSE_PARAMS,\n",
    ")\n",
    "\n",
    "# set the initial state to the start of the reference trajectory\n",
    "th_0 = traj_ts[\"th_ts\"][0]\n",
    "th_d_0 = traj_ts[\"th_d_ts\"][0]\n",
    "\n",
    "\n",
    "# define the feedback function that implements the GP-based controller\n",
    "def ctrl_fb(th: Array, th_d: Array, th_des: Array, th_d_des: Array) -> Array:\n",
    "    \"\"\"\n",
    "    GP-based feedback controller.\n",
    "    Args:\n",
    "        th: link angles. Shape: (2,)\n",
    "        th_d: link velocities. Shape: (2,)\n",
    "        th_des: desired link angles. Shape: (2,)\n",
    "        th_d_des: desired link velocities. Shape: (2,)\n",
    "    Returns:\n",
    "        tau_gp: link torques computed by the GP-based controller. Shape: (2,)\n",
    "    \"\"\"\n",
    "    # compute the normalized joint angles (i.e., relative angles) from the link angles\n",
    "    th_rel = normalize_link_angles(jnp.array([th[0], th[1] - th[0]]))\n",
    "\n",
    "    # construct input for GP\n",
    "    gp_input = torch.tensor(np.array(th_rel)).unsqueeze(0)\n",
    "\n",
    "    # evaluate GP output and use the mean as the controller action\n",
    "    # gp_output =\n",
    "    # gp_mean =\n",
    "    # kp =  # proportional gain in range [200, 1000]\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    dq = gp_mean\n",
    "    Kp = kp * np.eye(2)  # [Nm/rad]\n",
    "    tau_gp = Kp @ dq\n",
    "\n",
    "    return tau_gp\n",
    "\n",
    "\n",
    "# simulate the robot together in closed loop with the GP-based controller\n",
    "print(\"starting simulation\")\n",
    "sim_ts = simulate_robot(\n",
    "    ROBOT_PARAMS,\n",
    "    t_ts=t_ts,\n",
    "    th_0=th_0,\n",
    "    th_d_0=th_d_0,\n",
    "    ctrl_fb=ctrl_fb,\n",
    "    jit_compile=False,\n",
    ")\n",
    "print(\"finished simulation\")\n",
    "\n",
    "if not AUTOGRADING:\n",
    "    print(\"producing animation\")\n",
    "    ani = animate_robot(\n",
    "        ROBOT_PARAMS,\n",
    "        traj_ts=traj_ts,\n",
    "        sim_ts=sim_ts,\n",
    "        step_skip=5,\n",
    "        show=False,\n",
    "        filepath=str(\n",
    "            outputs_dir / f\"task_3g_robot_animation_behavioural_cloning_delta.mp4\"\n",
    "        ),\n",
    "    )\n",
    "    display(HTML(ani.to_html5_video()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89977466",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fdb6bd802f35ce49308e622e3e929242",
     "grade": false,
     "grade_id": "cell-3a5ec153c4acf8b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3g-5 EXPLAIN WHY THE CONTROL WITH THE GP IS NOT GOOD ENOUGH (2p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5186a7eb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec24d29b1f2d886fe045ccbd3860994a",
     "grade": true,
     "grade_id": "cell-c02d537c99eea70e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c6df07",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25f552791c2e9f6a2e06963c230a3f42",
     "grade": true,
     "grade_id": "cell-8a7748868488001d",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe9b79c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "68b53d44402553de475d65b096061da9",
     "grade": false,
     "grade_id": "cell-70b93fe34c02ce02",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3g-6 ADD A MINIMIZATION OF VARIANCE ON TOP OF THE PREVIOUS CONTROLLER (1p)\n",
    "In order to increase the performance of the learned torque behaviour, we are going to add a delta to the prediction towards direction of maximum decrease of the predicted epistemic uncertainty, i.e. in the opposite direction of the gradient of the variance of the GP prediction. We also going to add some damping to the control law to avoid oscillations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd26ed2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e040f3c341e2206e1875dcf09128896",
     "grade": false,
     "grade_id": "cell-900392818c944f06",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    " You need to\n",
    " - make prediction of mean and standard deviation of the GP prediction\n",
    " - compute the gradient of the variance of the GP prediction with respect to the input (check the Model class to pick the right method, do not implement it yourself)\n",
    " - define the new delta in the negative direction of the gradient, proportional to the standard deviation of the GP prediction\n",
    " - tune the proportional and the derivative gain of the controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd139c6e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38741018e752049193c184587859f4cc",
     "grade": true,
     "grade_id": "cell-c5c08f305c5926d9",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# import the feedforward gravity compensation controller from problem_2/controllers.ipynb\n",
    "sys.path.insert(0, Path.cwd().parent / \"problem_2\")\n",
    "from ipynb.fs.full.controllers import ctrl_ff_gravity_compensation\n",
    "\n",
    "# define feedforward gravity compensation controller\n",
    "ctrl_ff = partial(\n",
    "    ctrl_ff_gravity_compensation, partial(dynamical_matrices, ROBOT_PARAMS)\n",
    ")\n",
    "\n",
    "# run closed-loop simulation with GP-based controller\n",
    "sim_dt = 0.01\n",
    "sim_duration = 12.0 \n",
    "\n",
    "# define time steps\n",
    "t_ts = sim_dt * jnp.arange(int(sim_duration / sim_dt))\n",
    "\n",
    "# generate reference trajectory\n",
    "traj_ts = generate_ellipse_trajectory(\n",
    "    rp=ROBOT_PARAMS,\n",
    "    t_ts=t_ts,\n",
    "    **ELLIPSE_PARAMS,\n",
    ")\n",
    "\n",
    "# set the initial state to the start of the reference trajectory\n",
    "th_0 = traj_ts[\"th_ts\"][0]\n",
    "th_d_0 = traj_ts[\"th_d_ts\"][0]\n",
    "\n",
    "\n",
    "# define the feedback function that implements the GP-based controller\n",
    "def ctrl_fb(th: Array, th_d: Array, th_des: Array, th_d_des: Array) -> Array:\n",
    "    \"\"\"\n",
    "    GP-based feedback controller.\n",
    "    Args:\n",
    "        th: link angles. Shape: (2,)\n",
    "        th_d: link velocities. Shape: (2,)\n",
    "        th_des: desired link angles. Shape: (2,)\n",
    "        th_d_des: desired link velocities. Shape: (2,)\n",
    "    Returns:\n",
    "        tau_gp: link torques computed by the GP-based controller. Shape: (2,)\n",
    "    \"\"\"\n",
    "    # compute the normalized joint angles (i.e., relative angles) from the link angles\n",
    "    th_rel = normalize_link_angles(jnp.array([th[0], th[1] - th[0]]))\n",
    "\n",
    "    # construct input for GP\n",
    "    gp_input = torch.tensor(np.array(th_rel)).unsqueeze(0)\n",
    "\n",
    "    # evaluate GP output and use the mean as the controller action\n",
    "    # gp_output =\n",
    "    # gp_mean =\n",
    "    # gp_variance_gradient =\n",
    "    # delta_variance = - sigma * sign(gradient)\n",
    "    # kp =  # proportional gain in range [200, 1000]\n",
    "    # kd =  # derivative gain in range [1,5]\n",
    "    # k_var =  # variance minimization gain in range [0,2]\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # move the delta attractor in the direction of minimum uncertainty\n",
    "    dq = gp_mean + k_var * delta_variance\n",
    "\n",
    "    Kp = kp * np.eye(2)  # [Nm/rad]\n",
    "    Kd = kd * np.eye(2)  # [Nm s/rad]\n",
    "\n",
    "    tau_gp = Kp @ dq + Kd @ (-th_d)\n",
    "\n",
    "    return tau_gp\n",
    "\n",
    "\n",
    "# simulate the robot together in closed loop with the GP-based controller\n",
    "print(\"starting simulation\")\n",
    "sim_ts = simulate_robot(\n",
    "    ROBOT_PARAMS,\n",
    "    t_ts=t_ts,\n",
    "    th_0=th_0,\n",
    "    th_d_0=th_d_0,\n",
    "    ctrl_ff=ctrl_ff,\n",
    "    ctrl_fb=ctrl_fb,\n",
    "    jit_compile=False,\n",
    ")\n",
    "print(\"finished simulation\")\n",
    "\n",
    "if not AUTOGRADING:\n",
    "    print(\"producing animation\")\n",
    "    ani = animate_robot(\n",
    "        ROBOT_PARAMS,\n",
    "        traj_ts=traj_ts,\n",
    "        sim_ts=sim_ts,\n",
    "        step_skip=5,\n",
    "        show=False,\n",
    "        filepath=str(\n",
    "            outputs_dir\n",
    "            / f\"task_3g_robot_animation_behavioural_cloning_delta_variance_minimization.mp4\"\n",
    "        ),\n",
    "    )\n",
    "    display(HTML(ani.to_html5_video()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f61131",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0daf8c7bc2d48d0d363f59519dfed01b",
     "grade": false,
     "grade_id": "cell-7b8adf15393dff30",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3g-7 IT LOOKS LIKE THAT THE PERFORMANCE IMPROVED A LOT. WHY? EXPLAIN YOUR ANSWER. (2p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a0cb7e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d6ad91c26eb3042745a74cfd8cf08b8",
     "grade": false,
     "grade_id": "cell-fc90cf33df0c48b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfde077",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a9080b612a3f4bfc75f5fe6e61a561b",
     "grade": true,
     "grade_id": "cell-dc6a10bdeca5c37f",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
